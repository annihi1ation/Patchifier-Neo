{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# preparing mtat data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torchmetric\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.functional as AF\n",
    "import torchaudio.transforms as AT\n",
    "import torchvision.transforms as VT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "sample_rate = 22050\n",
    "top_db = 80\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "ampl2db = AT.AmplitudeToDB(top_db=top_db)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "fma_path = 'mtat_wav'\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories\n",
    "    # names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "\n",
    "    return allFiles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/16283 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ab39625ef444f189f5cdeab5cd63544"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mel_list = []\n",
    "'''\n",
    "Here to add the mtat data\n",
    "'''\n",
    "file_path = getListOfFiles('MTAT HERE')\n",
    "for wav_path in tqdm(file_path):\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    except RuntimeError:\n",
    "        print(wav_path)\n",
    "        continue\n",
    "    melspect = mel_spectrogram(waveform)\n",
    "    melspect = ampl2db(melspect) * 0.01\n",
    "    # print(melspect.shape)\n",
    "    mel_list.append(melspect)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mtat dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio.transforms as AT\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class MuseData(Dataset):\n",
    "    def __init__(self, data, transform, mode='train', max_len=25):\n",
    "        # processed_data = []\n",
    "\n",
    "        x_shape = []\n",
    "        for idx, l in enumerate(data):\n",
    "            try:\n",
    "                x_shape.append(l.shape[-1])\n",
    "            except ValueError:\n",
    "                print(idx)\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ori_width = self.data[0].shape[-1]\n",
    "        ori_height = self.data[0].shape[-2]\n",
    "\n",
    "        width = random.randint(int(ori_width * 0.9), int(ori_width * 1.2))\n",
    "        scaler = VT.Resize((ori_height, width))\n",
    "        cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2))\n",
    "        # cropper(scaler(mel_list[0])).shape\n",
    "        brightness = random.uniform(0.9, 1.1)\n",
    "        mel = scaler(self.data[idx])\n",
    "        mel = cropper(mel) * brightness\n",
    "\n",
    "        split_mel = []\n",
    "\n",
    "        for idx in range(self.max_len):\n",
    "\n",
    "            piece = mel[:, :, idx*ori_height//2: (idx+1)*ori_height//2]\n",
    "            if piece.shape[-1] != ori_height//2:\n",
    "                print('Error piece')\n",
    "\n",
    "            split_mel.append(piece)\n",
    "        split_mel = torch.stack(split_mel, dim=0)\n",
    "        return split_mel\n",
    "\n",
    "\n",
    "class VAEDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        ori_width = self.data[0].shape[-1]\n",
    "        ori_height = self.data[0].shape[-2]\n",
    "        width = random.randint(int(ori_width * 0.9), int(ori_width * 1.2))\n",
    "        scaler = VT.Resize((ori_height, width))\n",
    "        brightness = random.uniform(0.9, 1.1)\n",
    "\n",
    "        mel = scaler(self.data[idx]) * brightness\n",
    "\n",
    "        max_pos = mel.shape[2] -( ori_height // 2 + 1)\n",
    "        sampled_pos = random.randint(0, max_pos)\n",
    "        sample = mel[:, :, sampled_pos:sampled_pos+ori_height//2]\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "mel_transform = nn.Sequential(\n",
    "    AT.FrequencyMasking(128),\n",
    "    AT.TimeMasking(128)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.2985, -0.2758, -0.2557,  ..., -0.2686, -0.2635, -0.3103],\n         [-0.2013, -0.1682, -0.1752,  ..., -0.0987, -0.1230, -0.1446],\n         [-0.1107, -0.0960, -0.1197,  ..., -0.0247, -0.0536, -0.0883],\n         ...,\n         [-0.4735, -0.4841, -0.4905,  ..., -0.5111, -0.5162, -0.5406],\n         [-0.5138, -0.5438, -0.5489,  ..., -0.5805, -0.5787, -0.5838],\n         [-0.6193, -0.6193, -0.6193,  ..., -0.6193, -0.6193, -0.6193]]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_set = VAEDataset(mel_list)\n",
    "vae_set[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import random\n",
    "batch_size = 32\n",
    "random.shuffle(mel_list)\n",
    "\n",
    "\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8),len(dataset) - int(len(dataset) * 0.8)])\n",
    "train_set, val_set = MuseData(mel_list[:int(0.8 * len(mel_list))], None, 'val'), MuseData(mel_list[int(0.8*len(mel_list)):], None, 'val')\n",
    "# train_set = MuseData(train_data)\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# val_set = MuseData(val_data)\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "vae_loader = DataLoader(\n",
    "    vae_set,\n",
    "    batch_size=batch_size * 5,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "# from pytorch_metric_learning.losses import NTXentLoss\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertEncoder\n",
    "from info_nce import InfoNCE\n",
    "import torchvision.models as models\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, nf=32, num_res=0):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.models = nn.Sequential(\n",
    "            nn.Conv2d(1, nf, 7, 2, 3),\n",
    "            nn.BatchNorm2d(nf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf, nf*2, 3, 2, 1),\n",
    "            nn.BatchNorm2d(nf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*2, nf*4, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*4, nf*4, 3, 2, 1),\n",
    "            nn.BatchNorm2d(nf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*4, nf*8, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*8, nf*8, 3, 2, 1),\n",
    "            nn.BatchNorm2d(nf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*8, nf*8, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.out_layer = nn.Linear(6*nf*4, 512)\n",
    "\n",
    "    def forward(self, x, pretrain=False):\n",
    "        x = self.models(x)\n",
    "\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class FeatureExtractorDecoder(nn.Sequential):\n",
    "    def __init__(self, nf=32, num_res=2):\n",
    "        super(FeatureExtractorDecoder, self).__init__()\n",
    "\n",
    "\n",
    "        self.de_convs = nn.Sequential(\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf*8, nf*4, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf*4, nf*2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf*2, nf, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf, 1, 7, 1, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.shape[0], -1, 4, 2)\n",
    "        return self.de_convs(input)\n",
    "\n",
    "\n",
    "class InputRepresentation(nn.Module):\n",
    "    def __init__(self, max_len, input_dim, hidden_dim, do_rate=0.1):\n",
    "        super(InputRepresentation, self).__init__()\n",
    "        self.rep_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_len, hidden_dim)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.drop_out = nn.Dropout(do_rate)\n",
    "\n",
    "    def forward(self, input, pos):\n",
    "        rep = self.rep_embedding(input)\n",
    "        pos = self.pos_embedding(pos)\n",
    "        input_rep = rep + pos\n",
    "        # print(input_rep.dtype)\n",
    "        input_rep = self.layer_norm(input_rep)\n",
    "        input_rep = self.drop_out(input_rep)\n",
    "\n",
    "        return input_rep\n",
    "\n",
    "\n",
    "class Patchifier(nn.Module):\n",
    "    def __init__(self, fe_config, bert_config, bs=64, proj_dim=64):\n",
    "        super(Patchifier, self).__init__()\n",
    "        self.fe_config = fe_config\n",
    "        self.bert_config = bert_config\n",
    "        self.proj_dim = proj_dim\n",
    "        # num_embeddings, embedding_dim, commitment_c\n",
    "        self.feat_extr = FeatureExtractor(fe_config.nf)\n",
    "        self.feat_extr_decoder = FeatureExtractorDecoder(fe_config.nf)\n",
    "\n",
    "        self.embedder = InputRepresentation(\n",
    "                                            fe_config.max_len,\n",
    "                                            fe_config.nf*8 * 8,\n",
    "                                            bert_config.hidden_size,\n",
    "                                            bert_config.hidden_dropout_prob)\n",
    "        self.encoder = BertEncoder(bert_config)\n",
    "\n",
    "\n",
    "        self.inv_embedder = nn.Linear(bert_config.hidden_size, fe_config.nf*8 * 8)\n",
    "        self.diversity_weight = 0.1\n",
    "        # self.cl_loss_fn = InfoNCE(temperature=0.5)\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.cls_token = nn.Parameter((torch.ones([1, fe_config.nf*8 * 8], dtype=torch.float)).to(self.device))\n",
    "        self.mask_token =  nn.Parameter((torch.randn([fe_config.nf*8 * 8], dtype=torch.float)).to(self.device))\n",
    "\n",
    "    def load_fe(self, path):\n",
    "        self.feat_extr.load_state_dict(torch.load(path))\n",
    "\n",
    "    def load_bert(self, path):\n",
    "        self.encoder.load_state_dict(torch.load(path))\n",
    "\n",
    "    def load_fe_dec(self, path):\n",
    "        self.feat_extr_decoder.load_state_dict(torch.load(path))\n",
    "\n",
    "    def save_fe(self, path):\n",
    "        torch.save(self.feat_extr.state_dict(), path)\n",
    "\n",
    "    def save_bert(self, path):\n",
    "        torch.save(self.encoder.state_dict(), path)\n",
    "\n",
    "    def save_fe_dec(self, path):\n",
    "        torch.save(self.feat_extr_decoder.state_dict(), path)\n",
    "\n",
    "    def straight_forward(self, x, mode='vq'):\n",
    "        x = x.to(self.device)\n",
    "        bs = x.shape[0]\n",
    "        length = x.shape[1]\n",
    "        height = x.shape[3]\n",
    "        width = x.shape[4]\n",
    "\n",
    "        # feature extractor embeddings\n",
    "\n",
    "        feats = [self.cls_token.repeat(bs, 1)]\n",
    "        for idx in range(length):\n",
    "            mel = x[:, idx]\n",
    "            feat = self.feat_extr(mel)\n",
    "            feats.append(feat)\n",
    "\n",
    "        feats = torch.stack(feats, dim=1)\n",
    "\n",
    "\n",
    "        pos = torch.arange(0, length+1).repeat(bs, 1).to(self.device)\n",
    "        rep = self.embedder(feats, pos)\n",
    "        rep = self.encoder(rep).last_hidden_state\n",
    "\n",
    "        return rep\n",
    "\n",
    "    def mlm_pretrain(self, x, mask_rate=0.5):\n",
    "        x = x.to(self.device)\n",
    "        bs = x.shape[0]\n",
    "        length = x.shape[1]\n",
    "        height = x.shape[3]\n",
    "        width = x.shape[4]\n",
    "\n",
    "        # feature extractor embeddings\n",
    "\n",
    "        feats = [self.cls_token.repeat(bs, 1)]\n",
    "        for idx in range(length):\n",
    "            mel = x[:, idx]\n",
    "            feat = self.feat_extr(mel)\n",
    "            feats.append(feat)\n",
    "\n",
    "        feats = torch.stack(feats, dim=1)\n",
    "\n",
    "        '''\n",
    "\n",
    "            MASKING\n",
    "\n",
    "        '''\n",
    "\n",
    "        for i in range(feats.shape[0]):\n",
    "            for j in range(1, feats.shape[1]):\n",
    "                if random.random() < mask_rate:\n",
    "                    feats[i,j] = self.mask_token\n",
    "\n",
    "        pos = torch.arange(0, length+1).repeat(bs, 1).to(self.device)\n",
    "        rep = self.embedder(feats, pos)\n",
    "        rep = self.encoder(rep).last_hidden_state\n",
    "\n",
    "        # MLM loss\n",
    "\n",
    "        de_embd = self.inv_embedder(rep[:, 1:])\n",
    "\n",
    "        recons_feats = []\n",
    "        for idx in range(length):\n",
    "            rec_feat = de_embd[:, idx]\n",
    "            rec_feat = self.feat_extr_decoder(rec_feat)\n",
    "            recons_feats.append(rec_feat)\n",
    "        recons = torch.stack(recons_feats, dim=1)\n",
    "\n",
    "        loss = F.mse_loss(recons, x)\n",
    "        return loss\n",
    "\n",
    "    def ae_forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        recon_x = self.feat_extr_decoder(self.feat_extr(x))\n",
    "        loss = F.mse_loss(recon_x, x)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, mode='mlm', mask_rate=0.5):\n",
    "        if mode == 'mlm' and mask_rate > 0.:\n",
    "            loss = self.mlm_forward(x, mask_rate=mask_rate)\n",
    "            return loss\n",
    "        elif mode == 'ae':\n",
    "            loss = self.ae_forward(x),\n",
    "            return loss\n",
    "        else:\n",
    "            return self.straight_forward(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class ConfigFE:\n",
    "    def __init__(self, nf, num_vars, groups, combine_groups, vq_dim, max_len):\n",
    "        self.nf = nf\n",
    "        self.num_vars = num_vars\n",
    "        self.groups = groups\n",
    "        self.combine_groups = combine_groups\n",
    "        self.vq_dim = vq_dim\n",
    "        self.max_len = max_len\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6a283b2bd154b43a953a2495727b414"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m epoch_losses \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     11\u001B[0m patchifier\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m vae_loader:\n\u001B[0;32m     14\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     15\u001B[0m     loss \u001B[38;5;241m=\u001B[39m patchifier\u001B[38;5;241m.\u001B[39mae_forward(x)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    720\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 721\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    723\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36mVAEDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     59\u001B[0m scaler \u001B[38;5;241m=\u001B[39m VT\u001B[38;5;241m.\u001B[39mResize((ori_height, width))\n\u001B[0;32m     60\u001B[0m brightness \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m0.9\u001B[39m, \u001B[38;5;241m1.1\u001B[39m)\n\u001B[1;32m---> 62\u001B[0m mel \u001B[38;5;241m=\u001B[39m \u001B[43mscaler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m brightness\n\u001B[0;32m     64\u001B[0m max_pos \u001B[38;5;241m=\u001B[39m mel\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m( ori_height \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     65\u001B[0m sampled_pos \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, max_pos)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:349\u001B[0m, in \u001B[0;36mResize.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001B[39;00m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:432\u001B[0m, in \u001B[0;36mresize\u001B[1;34m(img, size, interpolation, max_size, antialias)\u001B[0m\n\u001B[0;32m    429\u001B[0m     pil_interpolation \u001B[38;5;241m=\u001B[39m pil_modes_mapping[interpolation]\n\u001B[0;32m    430\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F_pil\u001B[38;5;241m.\u001B[39mresize(img, size\u001B[38;5;241m=\u001B[39msize, interpolation\u001B[38;5;241m=\u001B[39mpil_interpolation, max_size\u001B[38;5;241m=\u001B[39mmax_size)\n\u001B[1;32m--> 432\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_t\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mantialias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:496\u001B[0m, in \u001B[0;36mresize\u001B[1;34m(img, size, interpolation, max_size, antialias)\u001B[0m\n\u001B[0;32m    493\u001B[0m \u001B[38;5;66;03m# Define align_corners to avoid warnings\u001B[39;00m\n\u001B[0;32m    494\u001B[0m align_corners \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m interpolation \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 496\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43minterpolate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnew_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_w\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malign_corners\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mantialias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m interpolation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m out_dtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39muint8:\n\u001B[0;32m    499\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m255\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3938\u001B[0m, in \u001B[0;36minterpolate\u001B[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001B[0m\n\u001B[0;32m   3936\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m antialias:\n\u001B[0;32m   3937\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39m_upsample_bilinear2d_aa(\u001B[38;5;28minput\u001B[39m, output_size, align_corners, scale_factors)\n\u001B[1;32m-> 3938\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsample_bilinear2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_factors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3939\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   3940\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m align_corners \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epochs = 5000\n",
    "fe_config = ConfigFE(16, 320, 2, True, 256, 40)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024, hidden_dropout_prob=0.3)\n",
    "patchifier = Patchifier(fe_config, bert_config).to('cuda')\n",
    "\n",
    "opt = torch.optim.AdamW(patchifier.parameters(), lr=lr)\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    epoch_losses = []\n",
    "    patchifier.train()\n",
    "\n",
    "    for x in vae_loader:\n",
    "        x = x.to('cuda')\n",
    "        loss = patchifier.ae_forward(x)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_losses.append(loss.cpu().data.item())\n",
    "\n",
    "    mean_loss = np.mean(np.array(epoch_losses))\n",
    "    if (e+1) % 50 == 0:\n",
    "        print('Loss at %d epoch: %.5f' % (e, mean_loss))\n",
    "\n",
    "# patchifier.save_fe('ckpt/ckpt_fe.pkl')\n",
    "# patchifier.save_fe_dec('ckpt/ckpt_fe_dec.pkl')\n",
    "# torch.save(opt.state_dict(), 'ckpt/autoencoder_opt.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downstream Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cde9077ace1a4d6699e76f4e63b08416"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "preparing data\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "'''\n",
    "Here to add gtzan path\n",
    "'''\n",
    "ori_path = 'GTZAN HERE'\n",
    "\n",
    "genres = ['reggae', 'pop', 'rock', 'hiphop', 'metal', 'country', 'disco', 'classical', 'blues', 'jazz']\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as AF\n",
    "import torchaudio.transforms as AT\n",
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "sample_rate = 22050\n",
    "top_db = 80\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "ampl2db = AT.AmplitudeToDB(top_db=top_db)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "genres_dict = {\n",
    "    'reggae': 0,\n",
    "    'pop': 1,\n",
    "    'rock': 2,\n",
    "    'hiphop': 3,\n",
    "    'metal': 4,\n",
    "    'country': 5,\n",
    "    'disco': 6,\n",
    "    'classical': 7,\n",
    "    'blues': 8,\n",
    "    'jazz': 9\n",
    "}\n",
    "\n",
    "mel_list = []\n",
    "for g in tqdm(genres):\n",
    "    for wav in os.listdir(os.path.join(ori_path, g)):\n",
    "        wav_path = os.path.join(ori_path, g, wav)\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        melspect = mel_spectrogram(waveform)\n",
    "        melspect = ampl2db(melspect)\n",
    "\n",
    "        assert genres_dict[g] != None\n",
    "        mel_list.append([melspect, torch.tensor(genres_dict[g])])\n",
    "\n",
    "mels = []\n",
    "for i, (elem, label) in enumerate(mel_list):\n",
    "    if elem.shape[-1] >= 1293:\n",
    "        elem = elem[..., :1293]\n",
    "        mels.append(elem)\n",
    "\n",
    "mels = torch.stack(mels, dim=0)\n",
    "mels = mels.detach() / 100\n",
    "\n",
    "new_mel_list = []\n",
    "for mel, (_, label) in zip(mels, mel_list):\n",
    "    new_mel_list.append([mel, label])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset\n",
    "'''\n",
    "\n",
    "class MuseData(Dataset):\n",
    "    def __init__(self, data, transform, mode='train', max_len=25):\n",
    "\n",
    "        x_shape = []\n",
    "        for idx, (x, l) in enumerate(data):\n",
    "            try:\n",
    "                x_shape.append(x.shape[-1])\n",
    "            except ValueError:\n",
    "                print(idx)\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data[idx]\n",
    "        ori_width = data.shape[-1]\n",
    "        ori_height = data.shape[-2]\n",
    "\n",
    "        if self.mode  == 'train':\n",
    "            width = random.randint(int(ori_width * 0.9), int(ori_width * 1.1))\n",
    "            scaler = VT.Resize((ori_height, width))\n",
    "            cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2 ))\n",
    "            # cropper(scaler(mel_list[0])).shape\n",
    "            brightness = random.uniform(0.9, 1.1)\n",
    "            mel = scaler(data)\n",
    "            mel = (cropper(mel) * brightness).detach()\n",
    "\n",
    "        else:\n",
    "            mel = data[..., :(self.max_len * ori_height) // 2 ]\n",
    "\n",
    "        split_mel = []\n",
    "\n",
    "        for idx in range(self.max_len):\n",
    "\n",
    "            piece = mel[:, :, idx*ori_height//2: (idx+1)*ori_height//2]\n",
    "            if piece.shape[-1] != ori_height//2:\n",
    "                print('Error piece')\n",
    "\n",
    "            split_mel.append(piece)\n",
    "        split_mel = torch.stack(split_mel, dim=0)\n",
    "        return split_mel, label\n",
    "\n",
    "\n",
    "import random\n",
    "batch_size = 32\n",
    "random.shuffle(new_mel_list)\n",
    "\n",
    "train_set, val_set = MuseData(new_mel_list[:int(0.8 * len(new_mel_list))], None, 'train'), MuseData(new_mel_list[int(0.8*len(new_mel_list)):], None, 'val')\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67aa6587585c475fb4d3c3aa45762201"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy in 10 epoch: 57.0312\n",
      "valid accuracy in 10 epoch: 55.5556\n",
      "------------------------------\n",
      "train accuracy in 20 epoch: 64.0625\n",
      "valid accuracy in 20 epoch: 62.1212\n",
      "------------------------------\n",
      "train accuracy in 30 epoch: 65.7552\n",
      "valid accuracy in 30 epoch: 62.1212\n",
      "------------------------------\n",
      "train accuracy in 40 epoch: 68.4896\n",
      "valid accuracy in 40 epoch: 64.1414\n",
      "------------------------------\n",
      "train accuracy in 50 epoch: 69.0104\n",
      "valid accuracy in 50 epoch: 64.6465\n",
      "------------------------------\n",
      "train accuracy in 60 epoch: 68.2292\n",
      "valid accuracy in 60 epoch: 66.6667\n",
      "------------------------------\n",
      "train accuracy in 70 epoch: 70.3125\n",
      "valid accuracy in 70 epoch: 67.1717\n",
      "------------------------------\n",
      "train accuracy in 80 epoch: 66.9271\n",
      "valid accuracy in 80 epoch: 63.6364\n",
      "------------------------------\n",
      "train accuracy in 90 epoch: 70.1823\n",
      "valid accuracy in 90 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 100 epoch: 68.4896\n",
      "valid accuracy in 100 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 110 epoch: 73.0469\n",
      "valid accuracy in 110 epoch: 69.6970\n",
      "------------------------------\n",
      "train accuracy in 120 epoch: 70.7031\n",
      "valid accuracy in 120 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 130 epoch: 68.3594\n",
      "valid accuracy in 130 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 140 epoch: 72.1354\n",
      "valid accuracy in 140 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 150 epoch: 73.0469\n",
      "valid accuracy in 150 epoch: 66.1616\n",
      "------------------------------\n",
      "train accuracy in 160 epoch: 76.9531\n",
      "valid accuracy in 160 epoch: 66.1616\n",
      "------------------------------\n",
      "train accuracy in 170 epoch: 73.6979\n",
      "valid accuracy in 170 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 180 epoch: 74.6094\n",
      "valid accuracy in 180 epoch: 67.1717\n",
      "------------------------------\n",
      "train accuracy in 190 epoch: 74.2188\n",
      "valid accuracy in 190 epoch: 69.6970\n",
      "------------------------------\n",
      "train accuracy in 200 epoch: 74.6094\n",
      "valid accuracy in 200 epoch: 66.1616\n",
      "------------------------------\n",
      "train accuracy in 210 epoch: 76.6927\n",
      "valid accuracy in 210 epoch: 63.6364\n",
      "------------------------------\n",
      "train accuracy in 220 epoch: 76.3021\n",
      "valid accuracy in 220 epoch: 68.1818\n",
      "------------------------------\n",
      "train accuracy in 230 epoch: 78.5156\n",
      "valid accuracy in 230 epoch: 67.1717\n",
      "------------------------------\n",
      "train accuracy in 240 epoch: 75.3906\n",
      "valid accuracy in 240 epoch: 69.6970\n",
      "------------------------------\n",
      "train accuracy in 250 epoch: 80.0781\n",
      "valid accuracy in 250 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 260 epoch: 77.7344\n",
      "valid accuracy in 260 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 270 epoch: 77.0833\n",
      "valid accuracy in 270 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 280 epoch: 80.2083\n",
      "valid accuracy in 280 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 290 epoch: 78.7760\n",
      "valid accuracy in 290 epoch: 71.7172\n",
      "------------------------------\n",
      "train accuracy in 300 epoch: 77.8646\n",
      "valid accuracy in 300 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 310 epoch: 77.3438\n",
      "valid accuracy in 310 epoch: 68.1818\n",
      "------------------------------\n",
      "train accuracy in 320 epoch: 80.5990\n",
      "valid accuracy in 320 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 330 epoch: 77.8646\n",
      "valid accuracy in 330 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 340 epoch: 81.1198\n",
      "valid accuracy in 340 epoch: 64.6465\n",
      "------------------------------\n",
      "train accuracy in 350 epoch: 80.7292\n",
      "valid accuracy in 350 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 360 epoch: 83.7240\n",
      "valid accuracy in 360 epoch: 67.1717\n",
      "------------------------------\n",
      "train accuracy in 370 epoch: 81.3802\n",
      "valid accuracy in 370 epoch: 66.6667\n",
      "------------------------------\n",
      "train accuracy in 380 epoch: 82.4219\n",
      "valid accuracy in 380 epoch: 68.1818\n",
      "------------------------------\n",
      "train accuracy in 390 epoch: 81.6406\n",
      "valid accuracy in 390 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 400 epoch: 82.6823\n",
      "valid accuracy in 400 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 410 epoch: 83.7240\n",
      "valid accuracy in 410 epoch: 64.1414\n",
      "------------------------------\n",
      "train accuracy in 420 epoch: 83.9844\n",
      "valid accuracy in 420 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 430 epoch: 83.7240\n",
      "valid accuracy in 430 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 440 epoch: 82.6823\n",
      "valid accuracy in 440 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 450 epoch: 84.1146\n",
      "valid accuracy in 450 epoch: 67.1717\n",
      "------------------------------\n",
      "train accuracy in 460 epoch: 83.7240\n",
      "valid accuracy in 460 epoch: 72.7273\n",
      "------------------------------\n",
      "train accuracy in 470 epoch: 85.0260\n",
      "valid accuracy in 470 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 480 epoch: 84.7656\n",
      "valid accuracy in 480 epoch: 69.6970\n",
      "------------------------------\n",
      "train accuracy in 490 epoch: 83.8542\n",
      "valid accuracy in 490 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 500 epoch: 86.3281\n",
      "valid accuracy in 500 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 510 epoch: 85.4167\n",
      "valid accuracy in 510 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 520 epoch: 85.0260\n",
      "valid accuracy in 520 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 530 epoch: 84.3750\n",
      "valid accuracy in 530 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 540 epoch: 86.0677\n",
      "valid accuracy in 540 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 550 epoch: 85.4167\n",
      "valid accuracy in 550 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 560 epoch: 85.8073\n",
      "valid accuracy in 560 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 570 epoch: 87.3698\n",
      "valid accuracy in 570 epoch: 69.6970\n",
      "------------------------------\n",
      "train accuracy in 580 epoch: 85.1562\n",
      "valid accuracy in 580 epoch: 71.2121\n",
      "------------------------------\n",
      "train accuracy in 590 epoch: 87.3698\n",
      "valid accuracy in 590 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 600 epoch: 88.2812\n",
      "valid accuracy in 600 epoch: 74.2424\n",
      "------------------------------\n",
      "train accuracy in 610 epoch: 85.8073\n",
      "valid accuracy in 610 epoch: 71.2121\n",
      "------------------------------\n",
      "train accuracy in 620 epoch: 85.8073\n",
      "valid accuracy in 620 epoch: 66.6667\n",
      "------------------------------\n",
      "train accuracy in 630 epoch: 85.5469\n",
      "valid accuracy in 630 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 640 epoch: 89.0625\n",
      "valid accuracy in 640 epoch: 69.6970\n",
      "------------------------------\n",
      "train accuracy in 650 epoch: 87.8906\n",
      "valid accuracy in 650 epoch: 74.7475\n",
      "------------------------------\n",
      "train accuracy in 660 epoch: 86.7188\n",
      "valid accuracy in 660 epoch: 72.7273\n",
      "------------------------------\n",
      "train accuracy in 670 epoch: 88.8021\n",
      "valid accuracy in 670 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 680 epoch: 88.2812\n",
      "valid accuracy in 680 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 690 epoch: 88.5417\n",
      "valid accuracy in 690 epoch: 72.2222\n",
      "------------------------------\n",
      "train accuracy in 700 epoch: 85.6771\n",
      "valid accuracy in 700 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 710 epoch: 87.6302\n",
      "valid accuracy in 710 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 720 epoch: 88.0208\n",
      "valid accuracy in 720 epoch: 66.6667\n",
      "------------------------------\n",
      "train accuracy in 730 epoch: 89.0625\n",
      "valid accuracy in 730 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 740 epoch: 89.1927\n",
      "valid accuracy in 740 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 750 epoch: 87.3698\n",
      "valid accuracy in 750 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 760 epoch: 88.4115\n",
      "valid accuracy in 760 epoch: 74.2424\n",
      "------------------------------\n",
      "train accuracy in 770 epoch: 88.5417\n",
      "valid accuracy in 770 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 780 epoch: 87.2396\n",
      "valid accuracy in 780 epoch: 67.6768\n",
      "------------------------------\n",
      "train accuracy in 790 epoch: 90.1042\n",
      "valid accuracy in 790 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 800 epoch: 89.5833\n",
      "valid accuracy in 800 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 810 epoch: 87.6302\n",
      "valid accuracy in 810 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 820 epoch: 87.8906\n",
      "valid accuracy in 820 epoch: 72.2222\n",
      "------------------------------\n",
      "train accuracy in 830 epoch: 88.0208\n",
      "valid accuracy in 830 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 840 epoch: 87.6302\n",
      "valid accuracy in 840 epoch: 72.2222\n",
      "------------------------------\n",
      "train accuracy in 850 epoch: 90.6250\n",
      "valid accuracy in 850 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 860 epoch: 86.9792\n",
      "valid accuracy in 860 epoch: 72.2222\n",
      "------------------------------\n",
      "train accuracy in 870 epoch: 89.9740\n",
      "valid accuracy in 870 epoch: 71.7172\n",
      "------------------------------\n",
      "train accuracy in 880 epoch: 88.5417\n",
      "valid accuracy in 880 epoch: 68.6869\n",
      "------------------------------\n",
      "train accuracy in 890 epoch: 88.9323\n",
      "valid accuracy in 890 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 900 epoch: 89.9740\n",
      "valid accuracy in 900 epoch: 70.2020\n",
      "------------------------------\n",
      "train accuracy in 910 epoch: 88.6719\n",
      "valid accuracy in 910 epoch: 73.7374\n",
      "------------------------------\n",
      "train accuracy in 920 epoch: 91.2760\n",
      "valid accuracy in 920 epoch: 70.7071\n",
      "------------------------------\n",
      "train accuracy in 930 epoch: 89.1927\n",
      "valid accuracy in 930 epoch: 71.7172\n",
      "------------------------------\n",
      "train accuracy in 940 epoch: 89.9740\n",
      "valid accuracy in 940 epoch: 71.2121\n",
      "------------------------------\n",
      "train accuracy in 950 epoch: 87.7604\n",
      "valid accuracy in 950 epoch: 69.1919\n",
      "------------------------------\n",
      "train accuracy in 960 epoch: 89.9740\n",
      "valid accuracy in 960 epoch: 71.2121\n",
      "------------------------------\n",
      "train accuracy in 970 epoch: 92.3177\n",
      "valid accuracy in 970 epoch: 72.7273\n",
      "------------------------------\n",
      "train accuracy in 980 epoch: 90.8854\n",
      "valid accuracy in 980 epoch: 68.1818\n",
      "------------------------------\n",
      "train accuracy in 990 epoch: 89.1927\n",
      "valid accuracy in 990 epoch: 71.2121\n",
      "------------------------------\n",
      "train accuracy in 1000 epoch: 90.1042\n",
      "valid accuracy in 1000 epoch: 68.6869\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Linear Prob\n",
    "'''\n",
    "\n",
    "class CLSF(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CLSF, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(config.hidden_size, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "lr = 1e-3\n",
    "epochs = 1000\n",
    "\n",
    "fe_config = ConfigFE(16, 320, 2, True, 256, 40)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024, hidden_dropout_prob=0.1)\n",
    "\n",
    "model = Patchifier(fe_config, bert_config).to('cuda')\n",
    "\n",
    "'''\n",
    "Here to add model path\n",
    "'''\n",
    "model.load_state_dict(torch.load('MODEL HERE'))\n",
    "\n",
    "# freeze model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class Pooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        pooled_output = self.dense(hidden_states)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "pooler = Pooler(bert_config).to('cuda')\n",
    "clsf = CLSF(bert_config).to('cuda')\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(list(model.parameters()) + list(pooler.parameters()) + list(clsf.parameters()), lr=lr,\n",
    "                        weight_decay=0.1)\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    # print(y_pred.shape)\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "acc_script = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    loss_script = []\n",
    "\n",
    "    model.train()\n",
    "    pooler.train()\n",
    "    clsf.train()\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    for x, label in train_loader:\n",
    "        x = x.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "\n",
    "        rep = model(x, mode='straight', mask_rate=0.5)\n",
    "\n",
    "        logit = clsf(pooler(rep[:, 0])).squeeze()\n",
    "        loss = crit(logit, label)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_script.append(loss.cpu().data.item())\n",
    "        _, pred = torch.max(logit.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (pred == label).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('train accuracy in %d epoch: %.4f' % ((epoch+1), accuracy))\n",
    "    mean_loss = np.mean(np.array(loss_script))\n",
    "    train_losses.append(mean_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        model.eval()\n",
    "        pooler.eval()\n",
    "        clsf.eval()\n",
    "\n",
    "        for x, label in val_loader:\n",
    "            x = x.to('cuda')\n",
    "            label = label.to('cuda')\n",
    "\n",
    "            rep = model(x, mode='straight', mask_rate=0.5)\n",
    "            # print(rep.shape)\n",
    "            logit = clsf(pooler(rep[:, 0])).squeeze()\n",
    "\n",
    "            _, pred = torch.max(logit.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (pred == label).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('valid accuracy in %d epoch: %.4f' % ((epoch+1), accuracy))\n",
    "            print('-' * 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downstream regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edf19df5b1f9460d96a1fa6ad62ba581"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\n",
      "0001\n",
      "0100\n",
      "0011\n",
      "0132\n",
      "0139\n",
      "0014\n",
      "0141\n",
      "0147\n",
      "0015\n",
      "0016\n",
      "0165\n",
      "0183\n",
      "0200\n",
      "0023\n",
      "0230\n",
      "0249\n",
      "0251\n",
      "0252\n",
      "0255\n",
      "0256\n",
      "0259\n",
      "0026\n",
      "0261\n",
      "0263\n",
      "0267\n",
      "0268\n",
      "0027\n",
      "0271\n",
      "0277\n",
      "0028\n",
      "0283\n",
      "0287\n",
      "0029\n",
      "0291\n",
      "0295\n",
      "0030\n",
      "0033\n",
      "0331\n",
      "0337\n",
      "0034\n",
      "0351\n",
      "0036\n",
      "0363\n",
      "0373\n",
      "0377\n",
      "0038\n",
      "0382\n",
      "0385\n",
      "0388\n",
      "0389\n",
      "0394\n",
      "0396\n",
      "0398\n",
      "0409\n",
      "0411\n",
      "0412\n",
      "0413\n",
      "0414\n",
      "0417\n",
      "0418\n",
      "0421\n",
      "0424\n",
      "0433\n",
      "0434\n",
      "0438\n",
      "0439\n",
      "0443\n",
      "0446\n",
      "0447\n",
      "0457\n",
      "0465\n",
      "0470\n",
      "0471\n",
      "0474\n",
      "0476\n",
      "0483\n",
      "0491\n",
      "0495\n",
      "0505\n",
      "0508\n",
      "0509\n",
      "0510\n",
      "0511\n",
      "0516\n",
      "0517\n",
      "0526\n",
      "0528\n",
      "0531\n",
      "0532\n",
      "0533\n",
      "0534\n",
      "0538\n",
      "0539\n",
      "0541\n",
      "0542\n",
      "0543\n",
      "0545\n",
      "0546\n",
      "0548\n",
      "0549\n",
      "0552\n",
      "0553\n",
      "0557\n",
      "0559\n",
      "0562\n",
      "0563\n",
      "0566\n",
      "0567\n",
      "0569\n",
      "0057\n",
      "0570\n",
      "0571\n",
      "0572\n",
      "0573\n",
      "0575\n",
      "0576\n",
      "0578\n",
      "0583\n",
      "0587\n",
      "0588\n",
      "0589\n",
      "0590\n",
      "0593\n",
      "0595\n",
      "0596\n",
      "0599\n",
      "0006\n",
      "0601\n",
      "0602\n",
      "0603\n",
      "0604\n",
      "0061\n",
      "0618\n",
      "0619\n",
      "0624\n",
      "0626\n",
      "0627\n",
      "0063\n",
      "0630\n",
      "0633\n",
      "0636\n",
      "0641\n",
      "0642\n",
      "0655\n",
      "0659\n",
      "0066\n",
      "0669\n",
      "0670\n",
      "0678\n",
      "0679\n",
      "0680\n",
      "0683\n",
      "0694\n",
      "0701\n",
      "0705\n",
      "0716\n",
      "0720\n",
      "0075\n",
      "0751\n",
      "0752\n",
      "0753\n",
      "0754\n",
      "0755\n",
      "0760\n",
      "0761\n",
      "0762\n",
      "0765\n",
      "0766\n",
      "0768\n",
      "0770\n",
      "0771\n",
      "0772\n",
      "0774\n",
      "0778\n",
      "0783\n",
      "0785\n",
      "0786\n",
      "0788\n",
      "0792\n",
      "0793\n",
      "0802\n",
      "0803\n",
      "0809\n",
      "0812\n",
      "0816\n",
      "0817\n",
      "0821\n",
      "0822\n",
      "0827\n",
      "0828\n",
      "0832\n",
      "0835\n",
      "0837\n",
      "0838\n",
      "0840\n",
      "0842\n",
      "0843\n",
      "0847\n",
      "0849\n",
      "0853\n",
      "0861\n",
      "0862\n",
      "0868\n",
      "0870\n",
      "0875\n",
      "0877\n",
      "0878\n",
      "0881\n",
      "0883\n",
      "0885\n",
      "0888\n",
      "0894\n",
      "0895\n",
      "0896\n",
      "0009\n",
      "0900\n",
      "0901\n",
      "0905\n",
      "0906\n",
      "0907\n",
      "0912\n",
      "0914\n",
      "0916\n",
      "0917\n",
      "0918\n",
      "0919\n",
      "0920\n",
      "0922\n",
      "0923\n",
      "0927\n",
      "0929\n",
      "0930\n",
      "0933\n",
      "0935\n",
      "0937\n",
      "0094\n",
      "0940\n",
      "0943\n",
      "0946\n",
      "0947\n",
      "0948\n",
      "0950\n",
      "0951\n",
      "0953\n",
      "0963\n",
      "0965\n",
      "0966\n",
      "0969\n",
      "0097\n",
      "0971\n",
      "0972\n",
      "0975\n",
      "0982\n",
      "0984\n",
      "0992\n",
      "0998\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "preparing data\n",
    "'''\n",
    "import json\n",
    "def parse_annotation_file(json_file):\n",
    "    tracks = {}\n",
    "    with open(json_file) as f:\n",
    "        examples = json.load(f)\n",
    "        for song_id in examples:\n",
    "            tracks[song_id] = {\n",
    "                'track_id': examples[song_id]['extra']['songs_info']['song_id'],\n",
    "                'split': examples[song_id]['split'],\n",
    "                'labels': examples[song_id]['y']\n",
    "            }\n",
    "    return tracks\n",
    "\n",
    "'''\n",
    "here to add emo music annotation\n",
    "'''\n",
    "\n",
    "infors = parse_annotation_file('ANNOTATION HERE')\n",
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "sample_rate = 44100\n",
    "top_db = 80\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "ampl2db = AT.AmplitudeToDB(top_db=top_db)\n",
    "\n",
    "mel_list = []\n",
    "\n",
    "'''\n",
    "Here to add emomusic path\n",
    "'''\n",
    "\n",
    "file_path = getListOfFiles('emo music')\n",
    "for wav_path in tqdm(file_path):\n",
    "    wav_id = wav_path[10: -4].zfill(4)\n",
    "\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        emotion = infors[wav_id]['labels']\n",
    "    except RuntimeError:\n",
    "        print(wav_path)\n",
    "        continue\n",
    "    except KeyError:\n",
    "        print(wav_id)\n",
    "        continue\n",
    "    # scaler = VT.Resize((64, 1938))\n",
    "    melspect = mel_spectrogram(waveform)\n",
    "    melspect = ampl2db(melspect)\n",
    "    melspect = (melspect).detach() * 0.01\n",
    "    # print(melspect.shape)\n",
    "    mel_list.append([melspect, emotion])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset\n",
    "'''\n",
    "\n",
    "class MuseData(Dataset):\n",
    "    def __init__(self, data, transform='None', mode='train', max_len=25):\n",
    "        # processed_data = []\n",
    "\n",
    "        x_shape = []\n",
    "        for idx, (x, l) in enumerate(data):\n",
    "            try:\n",
    "                x_shape.append(x.shape[-1])\n",
    "            except ValueError:\n",
    "                print(idx)\n",
    "        # x_shape = [l.shape[-1] for (l, _) in data]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data[idx]\n",
    "        ori_width = data.shape[-1]\n",
    "        ori_height = data.shape[-2]\n",
    "\n",
    "        if self.mode  == 'train':\n",
    "            width = random.randint(int(ori_width * 0.9), int(ori_width * 1.1))\n",
    "            scaler = VT.Resize((ori_height, width))\n",
    "            cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2 ))\n",
    "            # cropper(scaler(mel_list[0])).shape\n",
    "            brightness = random.uniform(0.9, 1.1)\n",
    "            mel = scaler(data)\n",
    "            mel = (cropper(mel) * brightness).detach()\n",
    "\n",
    "        else:\n",
    "\n",
    "            mel = data[..., :(self.max_len * ori_height) // 2 ]\n",
    "\n",
    "        split_mel = []\n",
    "\n",
    "        for idx in range(self.max_len):\n",
    "\n",
    "            piece = mel[:, :, idx*ori_height//2: (idx+1)*ori_height//2]\n",
    "            if piece.shape[-1] != ori_height//2:\n",
    "                print('Error piece')\n",
    "\n",
    "            split_mel.append(piece)\n",
    "        split_mel = torch.stack(split_mel, dim=0)\n",
    "        return split_mel, torch.tensor(label[0]), torch.tensor(label[1])\n",
    "\n",
    "\n",
    "import random\n",
    "batch_size = 32\n",
    "random.shuffle(mel_list)\n",
    "\n",
    "\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8),len(dataset) - int(len(dataset) * 0.8)])\n",
    "train_set, val_set = MuseData(mel_list[:int(0.8 * len(mel_list))], None, 'train'), MuseData(mel_list[int(0.8*len(mel_list)):], None, 'val')\n",
    "# train_set = MuseData(train_data)\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# val_set = MuseData(val_data)\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Linear prob\n",
    "'''\n",
    "\n",
    "class CLSF(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.prob_valence = nn.Linear(config.hidden_size, 1)\n",
    "        self.prob_arousal = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.prob_valence(x), self.prob_arousal(x)\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 2000\n",
    "\n",
    "fe_config = ConfigFE(16, 320, 2, True, 256, 40)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024, hidden_dropout_prob=0.1)\n",
    "\n",
    "model = Patchifier(fe_config, bert_config).to('cuda')\n",
    "\n",
    "'''\n",
    "Add Model\n",
    "'''\n",
    "model.load_state_dict(torch.load('MODEL HERE'))\n",
    "\n",
    "for param in model.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "class Pooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        # mean_hidden = hidden_states.mean(1)\n",
    "        pooled_output = self.dense(hidden_states)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "pooler = Pooler(bert_config).to('cuda')\n",
    "clsf = CLSF(bert_config).to('cuda')\n",
    "crit = nn.MSELoss()\n",
    "opt = torch.optim.AdamW(list(model.parameters()) + list(pooler.parameters()) + list(clsf.parameters()), lr=lr,\n",
    "                        weight_decay=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchmetrics import R2Score\n",
    "import torchmetrics\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "scorer = R2Score().to('cuda')\n",
    "train_losses = []\n",
    "acc_script = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    loss_script = []\n",
    "\n",
    "    model.train()\n",
    "    pooler.train()\n",
    "    clsf.train()\n",
    "\n",
    "    flag = 0\n",
    "    for x, label_v, label_a in train_loader:\n",
    "        x = x.to('cuda')\n",
    "        label_v = label_v.to('cuda')\n",
    "        label_a = label_a.to('cuda')\n",
    "\n",
    "        rep = model(x, mode='straight')\n",
    "\n",
    "        logit_v, logit_a = clsf(pooler(rep[:, 1:].mean(1)))\n",
    "        logit_v, logit_a = logit_v.squeeze(-1), logit_a.squeeze(-1)\n",
    "\n",
    "        loss = crit(logit_v, label_v) + crit(logit_a, label_a)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_script.append(loss.cpu().data.item())\n",
    "        if flag == 0:\n",
    "            total_label_v, total_label_a = label_v.data, label_a.data\n",
    "            total_logit_v, total_logit_a = logit_v.data, logit_a.data\n",
    "            flag = 1\n",
    "        else:\n",
    "            total_label_v = torch.cat([total_label_v, label_v.data], dim=0)\n",
    "            total_label_a = torch.cat([total_label_a, label_a.data], dim=0)\n",
    "\n",
    "            total_logit_v = torch.cat([total_logit_v, logit_v.data], dim=0)\n",
    "            total_logit_a = torch.cat([total_logit_a, logit_a.data], dim=0)\n",
    "\n",
    "    r2_v = scorer(total_logit_v, total_label_v)\n",
    "    r2_a = scorer(total_logit_a, total_label_a)\n",
    "\n",
    "    mean_loss = np.mean(np.array(loss_script))\n",
    "    train_losses.append(mean_loss)\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print('train loss in %d epoch: %.4f' % ((epoch+1), mean_loss))\n",
    "        print('r2 score valence: %.4f' % r2_v)\n",
    "        print('r2 score arousal: %.4f' % r2_a)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        model.eval()\n",
    "        pooler.eval()\n",
    "        clsf.eval()\n",
    "\n",
    "        for x, label_v, label_a in train_loader:\n",
    "            x = x.to('cuda')\n",
    "            label_v = label_v.to('cuda')\n",
    "            label_a = label_a.to('cuda')\n",
    "\n",
    "            rep = model(x, mode='straight', mask_rate=0.5)\n",
    "            # print(rep.shape)\n",
    "            logit_v, logit_a = clsf(pooler(rep[:, 1:].mean(1)))\n",
    "            logit_v, logit_a = logit_v.squeeze(-1), logit_a.squeeze(-1)\n",
    "\n",
    "            if flag == 0:\n",
    "                total_label_v, total_label_a = label_v.data, label_a.data\n",
    "                total_logit_v, total_logit_a = logit_v.data, logit_a.data\n",
    "                flag = 1\n",
    "            else:\n",
    "                total_label_v = torch.cat([total_label_v, label_v.data], dim=0)\n",
    "                total_label_a = torch.cat([total_label_a, label_a.data], dim=0)\n",
    "\n",
    "                total_logit_v = torch.cat([total_logit_v, logit_v.data], dim=0)\n",
    "                total_logit_a = torch.cat([total_logit_a, logit_a.data], dim=0)\n",
    "\n",
    "\n",
    "        r2_v = scorer(total_logit_v, total_label_v)\n",
    "        r2_a = scorer(total_logit_a, total_label_a)\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print('r2 score in %d epoch: %.4f, %.4f' % ((epoch+1), r2_v, r2_a))\n",
    "            print('-' * 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
