{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.functional as AF\n",
    "import torchaudio.transforms as AT\n",
    "import torchvision.transforms as VT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "sample_rate = 22050\n",
    "top_db = 80\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "ampl2db = AT.AmplitudeToDB(top_db=top_db)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "genres_dict = {\n",
    "    'reggae': 0,\n",
    "    'pop': 1,\n",
    "    'rock': 2,\n",
    "    'hiphop': 3,\n",
    "    'metal': 4,\n",
    "    'country': 5,\n",
    "    'disco': 6,\n",
    "    'classical': 7,\n",
    "    'blues': 8,\n",
    "    'jazz': 9\n",
    "\n",
    "}\n",
    "\n",
    "fma_path = 'fma_small'\n",
    "def getListOfFiles(dirName):\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "\n",
    "    for entry in listOfFile:\n",
    "\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "\n",
    "    return allFiles\n",
    "\n",
    "len(getListOfFiles(fma_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "mtat_path = getListOfFiles('mtat')\n",
    "for i, mp3_path in tqdm(enumerate(mtat_path)):\n",
    "    try:\n",
    "        sound = AudioSegment.from_mp3(mp3_path)\n",
    "        dst = os.path.join('mtat_wav', '%d.wav' % i)\n",
    "        sound.export(dst, format=\"wav\")\n",
    "    except Exception:\n",
    "        print(mp3_path)\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mel_list = []\n",
    "file_path = getListOfFiles('mtat_wav')\n",
    "for wav_path in tqdm(file_path):\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    except RuntimeError:\n",
    "        print(wav_path)\n",
    "        continue\n",
    "    melspect = mel_spectrogram(waveform)\n",
    "    melspect = ampl2db(melspect)\n",
    "    # print(melspect.shape)\n",
    "    mel_list.append(melspect)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.transforms as VT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio.transforms as AT\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class MuseData(Dataset):\n",
    "    def __init__(self, data, transform, mode='train', max_len=25):\n",
    "        # processed_data = []\n",
    "\n",
    "        x_shape = []\n",
    "        for idx, l in enumerate(data):\n",
    "            try:\n",
    "                x_shape.append(l.shape[-1])\n",
    "            except ValueError:\n",
    "                print(idx)\n",
    "        # x_shape = [l.shape[-1] for (l, _) in data]\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ori_width = self.data[0].shape[-1]\n",
    "        ori_height = self.data[0].shape[-2]\n",
    "\n",
    "        width = random.randint(int(ori_width * 0.9), int(ori_width * 1.2))\n",
    "        scaler = VT.Resize((ori_height, width))\n",
    "        cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2))\n",
    "        # cropper(scaler(mel_list[0])).shape\n",
    "        brightness = random.uniform(0.9, 1.1)\n",
    "        mel = scaler(self.data[idx])\n",
    "        mel = cropper(mel) * brightness\n",
    "        # if self.mode == 'train':\n",
    "        #     mel = self.transform(mel)\n",
    "        split_mel = []\n",
    "        # print(mel.shape[2])\n",
    "        for idx in range(self.max_len):\n",
    "\n",
    "            piece = mel[:, :, idx*ori_height//2: (idx+1)*ori_height//2]\n",
    "            if piece.shape[-1] != ori_height//2:\n",
    "                print('Error piece')\n",
    "\n",
    "            # piece = torch.zeros(piece)\n",
    "            split_mel.append(piece)\n",
    "        split_mel = torch.stack(split_mel, dim=0)\n",
    "        return split_mel\n",
    "\n",
    "\n",
    "class VAEDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        ori_width = self.data[0].shape[-1]\n",
    "        ori_height = self.data[0].shape[-2]\n",
    "        width = random.randint(int(ori_width * 0.9), int(ori_width * 1.2))\n",
    "        scaler = VT.Resize((ori_height, width))\n",
    "        brightness = random.uniform(0.9, 1.1)\n",
    "\n",
    "        mel = scaler(self.data[idx]) * brightness\n",
    "\n",
    "        max_pos = mel.shape[2] -( ori_height // 2 + 1)\n",
    "        sampled_pos = random.randint(0, max_pos)\n",
    "        sample = mel[:, :, sampled_pos:sampled_pos+ori_height//2]\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "mel_transform = nn.Sequential(\n",
    "    AT.FrequencyMasking(128),\n",
    "    AT.TimeMasking(128)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import random\n",
    "batch_size = 32\n",
    "random.shuffle(mel_list)\n",
    "\n",
    "\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8),len(dataset) - int(len(dataset) * 0.8)])\n",
    "train_set, val_set = MuseData(mel_list[:int(0.8 * len(mel_list))], None, 'val'), MuseData(mel_list[int(0.8*len(mel_list)):], None, 'val')\n",
    "# train_set = MuseData(train_data)\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# val_set = MuseData(val_data)\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "vae_loader = DataLoader(\n",
    "    vae_set,\n",
    "    batch_size=batch_size * 5,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertEncoder\n",
    "import torch\n",
    "\n",
    "config = BertConfig(num_hidden_layers = 6, num_attention_heads=6)\n",
    "encoder = BertEncoder(config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "# from pytorch_metric_learning.losses import NTXentLoss\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertEncoder\n",
    "from info_nce import InfoNCE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, nf=32, num_res=0):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.models = nn.Sequential(\n",
    "            nn.Conv2d(1, nf, 7, 2, 3),\n",
    "            nn.BatchNorm2d(nf),\n",
    "            nn.ReLU(True),\n",
    "            # nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(nf, nf*2, 3, 2, 1),\n",
    "            nn.BatchNorm2d(nf*2),\n",
    "            nn.ReLU(True),\n",
    "            # nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(nf*2, nf*4, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*4, nf*4, 3, 2, 1),\n",
    "            nn.BatchNorm2d(nf*4),\n",
    "            nn.ReLU(True),\n",
    "            # nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(nf*4, nf*8, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nf*8, nf*8, 3, 2, 1),\n",
    "            nn.BatchNorm2d(nf*8),\n",
    "            nn.ReLU(True),\n",
    "            # nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(nf*8, nf*8, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # nn.Conv2d(nf*8, nf*8, 3, 2, 1),\n",
    "            # nn.BatchNorm2d(nf*8),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.MaxPool2d(2, 2, 0),\n",
    "            # nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        # res_blocks = []\n",
    "        # for _ in range(num_res):\n",
    "        #     res_blocks.append(ResBlock(nf*8, nf*8))\n",
    "        #\n",
    "        # self.res_blocks = nn.Sequential(*res_blocks)\n",
    "        self.out_layer = nn.Linear(6*nf*4, 512)\n",
    "\n",
    "    def forward(self, x, pretrain=False):\n",
    "        x = self.models(x)\n",
    "        # x = self.res_blocks(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        # if pretrain:\n",
    "        #     return self.proj_head(x)\n",
    "        # else:\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class FeatureExtractorDecoder(nn.Sequential):\n",
    "    def __init__(self, nf=32, num_res=2):\n",
    "        super(FeatureExtractorDecoder, self).__init__()\n",
    "        # res_blocks = []\n",
    "        # for _ in range(num_res):\n",
    "        #     res_blocks.append(ResBlock(nf*8, nf*8))\n",
    "        # self.res_blocks = nn.Sequential(*res_blocks)\n",
    "\n",
    "        self.de_convs = nn.Sequential(\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            # nn.Conv2d(nf*8, nf*8, 3, 1, 1),\n",
    "            # nn.BatchNorm2d(nf*8),\n",
    "            # nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf*8, nf*4, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf*4, nf*2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf*2, nf, 3, 1, 1),\n",
    "            nn.BatchNorm2d(nf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(nf, 1, 7, 1, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.shape[0], -1, 4, 2)\n",
    "        return self.de_convs(input)\n",
    "\n",
    "\n",
    "class InputRepresentation(nn.Module):\n",
    "    def __init__(self, max_len, input_dim, hidden_dim, do_rate=0.1):\n",
    "        super(InputRepresentation, self).__init__()\n",
    "        self.rep_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_len, hidden_dim)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.drop_out = nn.Dropout(do_rate)\n",
    "\n",
    "    def forward(self, input, pos):\n",
    "        rep = self.rep_embedding(input)\n",
    "        pos = self.pos_embedding(pos)\n",
    "        input_rep = rep + pos\n",
    "        # print(input_rep.dtype)\n",
    "        input_rep = self.layer_norm(input_rep)\n",
    "        input_rep = self.drop_out(input_rep)\n",
    "\n",
    "        return input_rep\n",
    "\n",
    "# dim, num_vars, groups, combine_groups, vq_dim\n",
    "\n",
    "class UniSML(nn.Module):\n",
    "    def __init__(self, fe_config, bert_config, bs=64, proj_dim=64):\n",
    "        super(UniSML, self).__init__()\n",
    "        self.fe_config = fe_config\n",
    "        self.bert_config = bert_config\n",
    "        self.proj_dim = proj_dim\n",
    "        # num_embeddings, embedding_dim, commitment_c\n",
    "        self.feat_extr = FeatureExtractor(fe_config.nf)\n",
    "        self.feat_extr_decoder = FeatureExtractorDecoder(fe_config.nf)\n",
    "        # self.quantizer = KmeansVectorQuantizer(\n",
    "        #     fe_config.nf*8,\n",
    "        #     fe_config.num_vars,\n",
    "        #     fe_config.groups,\n",
    "        #     fe_config.combine_groups,\n",
    "        #     fe_config.vq_dim\n",
    "        #  )\n",
    "        self.embedder = InputRepresentation(\n",
    "                                            fe_config.max_len,\n",
    "                                            fe_config.nf*8 * 8,\n",
    "                                            bert_config.hidden_size,\n",
    "                                            bert_config.hidden_dropout_prob)\n",
    "        self.encoder = BertEncoder(bert_config)\n",
    "\n",
    "        # self.proj_fe = nn.Linear(fe_config.nf*8, proj_dim)\n",
    "        # self.proj_bert = nn.Linear(bert_config.hidden_size, proj_dim)\n",
    "        self.inv_embedder = nn.Linear(bert_config.hidden_size, fe_config.nf*8 * 8)\n",
    "        self.diversity_weight = 0.1\n",
    "        self.cl_loss_fn = InfoNCE(temperature=0.5)\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.cls_token = nn.Parameter((torch.ones([1, fe_config.nf*8 * 8], dtype=torch.float)).to(self.device))\n",
    "        self.mask_token =  nn.Parameter((torch.randn([fe_config.nf*8 * 8], dtype=torch.float)).to(self.device))\n",
    "\n",
    "    def load_fe(self, path):\n",
    "        self.feat_extr.load_state_dict(torch.load(path))\n",
    "\n",
    "    def load_bert(self, path):\n",
    "        self.encoder.load_state_dict(torch.load(path))\n",
    "\n",
    "    def load_fe_dec(self, path):\n",
    "        self.feat_extr_decoder.load_state_dict(torch.load(path))\n",
    "\n",
    "    def save_fe(self, path):\n",
    "        torch.save(self.feat_extr.state_dict(), path)\n",
    "\n",
    "    def save_bert(self, path):\n",
    "        torch.save(self.encoder.state_dict(), path)\n",
    "\n",
    "    def save_fe_dec(self, path):\n",
    "        torch.save(self.feat_extr_decoder.state_dict(), path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def mlm_pretrain(self, x, mask_rate=0.5):\n",
    "        x = x.to(self.device)\n",
    "        bs = x.shape[0]\n",
    "        length = x.shape[1]\n",
    "        height = x.shape[3]\n",
    "        width = x.shape[4]\n",
    "\n",
    "        # feature extractor embeddings\n",
    "\n",
    "        feats = [self.cls_token.repeat(bs, 1)]\n",
    "        for idx in range(length):\n",
    "            mel = x[:, idx]\n",
    "            feat = self.feat_extr(mel)\n",
    "            feats.append(feat)\n",
    "\n",
    "        feats = torch.stack(feats, dim=1)\n",
    "\n",
    "        # x = x.reshape(bs*length, 1, height, width)\n",
    "        # feats = self.feat_extr(x)\n",
    "        # feats = feats.reshape(bs, length, -1)\n",
    "        # print(\"feature extracting: \", time.time() - start_time)\n",
    "        # start_time= time.time()\n",
    "\n",
    "        '''\n",
    "\n",
    "            MASKING\n",
    "\n",
    "        '''\n",
    "\n",
    "        for i in range(feats.shape[0]):\n",
    "            for j in range(1, feats.shape[1]):\n",
    "                if random.random() < mask_rate:\n",
    "                    feats[i,j] = self.mask_token\n",
    "        # masked_indice = (torch.rand([bs, length]) > mask_rate).to(self.device)\n",
    "        # feats[~masked_indice] = self.mask_token\n",
    "\n",
    "        #\n",
    "        # print('Masking', time.time()-start_time)\n",
    "        # start_time = time.time()\n",
    "\n",
    "        pos = torch.arange(0, length+1).repeat(bs, 1).to(self.device)\n",
    "        rep = self.embedder(feats, pos)\n",
    "        rep = self.encoder(rep).last_hidden_state\n",
    "\n",
    "        # MLM loss\n",
    "\n",
    "        de_embd = self.inv_embedder(rep[:, 1:])\n",
    "        # print(de_embd.shape)\n",
    "        # print('transforming: ', time.time() - start_time)\n",
    "        # start_time = time.time()\n",
    "\n",
    "        # ori_list = torch.unbind(ori_feats, dim=1)\n",
    "        # latent_loss = F.mse_loss(de_embd, feats)\n",
    "        recons_feats = []\n",
    "        for idx in range(length):\n",
    "            rec_feat = de_embd[:, idx]\n",
    "            rec_feat = self.feat_extr_decoder(rec_feat)\n",
    "            recons_feats.append(rec_feat)\n",
    "        recons = torch.stack(recons_feats, dim=1)\n",
    "        # de_embd = de_embd.reshape(bs*length, -1)\n",
    "        # recons = self.feat_extr_decoder(de_embd)\n",
    "        # recons = recons.reshape(bs*length, 1, height, width)\n",
    "        # print(recons.shape)\n",
    "        # print('decoding: ', time.time() - start_time)\n",
    "        loss = F.mse_loss(recons, x)\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def straight_forward(self, x, mode='vq'):\n",
    "        x = x.to(self.device)\n",
    "        bs = x.shape[0]\n",
    "        length = x.shape[1]\n",
    "        height = x.shape[3]\n",
    "        width = x.shape[4]\n",
    "\n",
    "        # feature extractor embeddings\n",
    "\n",
    "        feats = [self.cls_token.repeat(bs, 1)]\n",
    "        for idx in range(length):\n",
    "            mel = x[:, idx]\n",
    "            feat = self.feat_extr(mel)\n",
    "            feats.append(feat)\n",
    "\n",
    "        feats = torch.stack(feats, dim=1)\n",
    "\n",
    "\n",
    "        pos = torch.arange(0, length+1).repeat(bs, 1).to(self.device)\n",
    "        rep = self.embedder(feats, pos)\n",
    "        rep = self.encoder(rep).last_hidden_state\n",
    "\n",
    "        return rep\n",
    "\n",
    "    def ae_forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        recon_x = self.feat_extr_decoder(self.feat_extr(x))\n",
    "        loss = F.mse_loss(recon_x, x)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, mode='mlm', mask_rate=0.5):\n",
    "        if mode == 'mlm' and mask_rate > 0.:\n",
    "            loss = self.mlm_forward(x, mask_rate=mask_rate)\n",
    "            return loss\n",
    "        elif mode == 'vq' and mask_rate > 0.:\n",
    "            loss = self.vq_wav2vec_forward(x, mask_rate=mask_rate)\n",
    "            return loss\n",
    "        elif mode == 'ae':\n",
    "            loss = self.ae_forward(x),\n",
    "            return loss\n",
    "        else:\n",
    "            return self.straight_forward(x)\n",
    "\n",
    "# dim, num_vars, groups, combine_groups, vq_dim\n",
    "class ConfigFE:\n",
    "    def __init__(self, nf, num_vars, groups, combine_groups, vq_dim, max_len):\n",
    "        self.nf = nf\n",
    "        self.num_vars = num_vars\n",
    "        self.groups = groups\n",
    "        self.combine_groups = combine_groups\n",
    "        self.vq_dim = vq_dim\n",
    "        self.max_len = max_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "fe_config = ConfigFE(32, 320, 2, True, 256, 25)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024)\n",
    "uni_sml = UniSML(fe_config, bert_config).to(device)\n",
    "\n",
    "lr = 3e-4\n",
    "epochs = 1000\n",
    "fe_config = ConfigFE(16, 320, 2, True, 256, 40)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024, hidden_dropout_prob=0.3)\n",
    "uni_sml = UniSML(fe_config, bert_config).to('cuda')\n",
    "\n",
    "opt = torch.optim.AdamW(uni_sml.parameters(), lr=lr)\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    epoch_losses = []\n",
    "    uni_sml.train()\n",
    "\n",
    "    for x in vae_loader:\n",
    "        x = x.to('cuda')\n",
    "        loss = uni_sml.ae_forward(x)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_losses.append(loss.cpu().data.item())\n",
    "\n",
    "    mean_loss = np.mean(np.array(epoch_losses))\n",
    "    if (e+1) % 50 == 0:\n",
    "        print('Loss at %d epoch: %.5f' % (e, mean_loss))\n",
    "\n",
    "uni_sml.save_fe('ckpt/ckpt_fe.pkl')\n",
    "uni_sml.save_fe_dec('ckpt/ckpt_fe_dec.pkl')\n",
    "torch.save(opt.state_dict(), 'ckpt/autoencoder_opt.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downstream"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "ori_path = 'Data/genres_original'\n",
    "\n",
    "genres = ['reggae', 'pop', 'rock', 'hiphop', 'metal', 'country', 'disco', 'classical', 'blues', 'jazz']\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as AF\n",
    "import torchaudio.transforms as AT\n",
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "sample_rate = 22050\n",
    "top_db = 80\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "ampl2db = AT.AmplitudeToDB(top_db=top_db)\n",
    "# melspec = mel_spectrogram(waveform)\n",
    "# melspec.shape\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "genres_dict = {\n",
    "    'reggae': 0,\n",
    "    'pop': 1,\n",
    "    'rock': 2,\n",
    "    'hiphop': 3,\n",
    "    'metal': 4,\n",
    "    'country': 5,\n",
    "    'disco': 6,\n",
    "    'classical': 7,\n",
    "    'blues': 8,\n",
    "    'jazz': 9\n",
    "\n",
    "}\n",
    "mel_list = []\n",
    "for g in tqdm(genres):\n",
    "    for wav in os.listdir(os.path.join(ori_path, g)):\n",
    "        wav_path = os.path.join(ori_path, g, wav)\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        except RuntimeError:\n",
    "            # print(wav_path)\n",
    "            continue\n",
    "        melspect = mel_spectrogram(waveform)\n",
    "        melspect = ampl2db(melspect)\n",
    "        # print(melspect.shape)\n",
    "        assert genres_dict[g] != None\n",
    "        mel_list.append([melspect, torch.tensor(genres_dict[g])])\n",
    "\n",
    "mels = []\n",
    "for i, (elem, label) in enumerate(mel_list):\n",
    "    if elem.shape[-1] >= 1293:\n",
    "        elem = elem[..., :1293]\n",
    "        mels.append(elem)\n",
    "\n",
    "mels = torch.stack(mels, dim=0)\n",
    "\n",
    "mels = mels.detach() / 100\n",
    "\n",
    "new_mel_list = []\n",
    "for mel, (_, label) in zip(mels, mel_list):\n",
    "    new_mel_list.append([mel, label])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MuseData(Dataset):\n",
    "    def __init__(self, data, transform, mode='train', max_len=25):\n",
    "        # processed_data = []\n",
    "\n",
    "        x_shape = []\n",
    "        for idx, (x, l) in enumerate(data):\n",
    "            try:\n",
    "                x_shape.append(x.shape[-1])\n",
    "            except ValueError:\n",
    "                print(idx)\n",
    "        # x_shape = [l.shape[-1] for (l, _) in data]\n",
    "        self.max_len = max_len\n",
    "        # self.length_per_sec = int(np.max(np.array(x_shape)) // 128)\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data[idx]\n",
    "        ori_width = data.shape[-1]\n",
    "        ori_height = data.shape[-2]\n",
    "\n",
    "        if self.mode  == 'train':\n",
    "            width = random.randint(int(ori_width * 0.9), int(ori_width * 1.1))\n",
    "            scaler = VT.Resize((ori_height, width))\n",
    "            cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2 ))\n",
    "            # cropper(scaler(mel_list[0])).shape\n",
    "            brightness = random.uniform(0.9, 1.1)\n",
    "            mel = scaler(data)\n",
    "            mel = (cropper(mel) * brightness).detach()\n",
    "            # if self.mode == 'train':\n",
    "            #     mel = self.transform(mel)\n",
    "        else:\n",
    "            # cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2))\n",
    "            # mel = cropper(data)\n",
    "            mel = data[..., :(self.max_len * ori_height) // 2 ]\n",
    "\n",
    "        split_mel = []\n",
    "        # print(mel.shape[2])\n",
    "        for idx in range(self.max_len):\n",
    "\n",
    "            piece = mel[:, :, idx*ori_height//2: (idx+1)*ori_height//2]\n",
    "            if piece.shape[-1] != ori_height//2:\n",
    "                print('Error piece')\n",
    "\n",
    "            # piece = torch.zeros(piece)\n",
    "            split_mel.append(piece)\n",
    "        split_mel = torch.stack(split_mel, dim=0)\n",
    "        return split_mel, label\n",
    "\n",
    "import random\n",
    "batch_size = 32\n",
    "random.shuffle(new_mel_list)\n",
    "\n",
    "\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8),len(dataset) - int(len(dataset) * 0.8)])\n",
    "train_set, val_set = MuseData(new_mel_list[:int(0.8 * len(new_mel_list))], None, 'train'), MuseData(new_mel_list[int(0.8*len(new_mel_list)):], None, 'val')\n",
    "# train_set = MuseData(train_data)\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# val_set = MuseData(val_data)\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class CLSF(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CLSF, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(config.hidden_size, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "lr = 1e-3\n",
    "epochs = 2000\n",
    "\n",
    "fe_config = ConfigFE(16, 320, 2, True, 256, 40)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024, hidden_dropout_prob=0.1)\n",
    "\n",
    "uni_sml = UniSML(fe_config, bert_config).to('cuda')\n",
    "uni_sml.load_state_dict(torch.load('ckpt/uni_sml.pkl'))\n",
    "\n",
    "for param in uni_sml.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class Pooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        # mean_hidden = hidden_states.mean(1)\n",
    "        pooled_output = self.dense(hidden_states)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "pooler = Pooler(bert_config).to('cuda')\n",
    "clsf = CLSF(bert_config).to('cuda')\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(list(uni_sml.parameters()) + list(pooler.parameters()) + list(clsf.parameters()), lr=lr,\n",
    "                        weight_decay=0.1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    # print(y_pred.shape)\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "acc_script = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    loss_script = []\n",
    "\n",
    "    uni_sml.train()\n",
    "    pooler.train()\n",
    "    clsf.train()\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    for x, label in train_loader:\n",
    "        x = x.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "\n",
    "        rep = uni_sml(x, mode='straight', mask_rate=0.5)\n",
    "\n",
    "        logit = clsf(pooler(rep[:, 0])).squeeze()\n",
    "        loss = crit(logit, label)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_script.append(loss.cpu().data.item())\n",
    "        _, pred = torch.max(logit.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (pred == label).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('train accuracy in %d epoch: %.4f' % ((epoch+1), accuracy))\n",
    "    mean_loss = np.mean(np.array(loss_script))\n",
    "    train_losses.append(mean_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        uni_sml.eval()\n",
    "        pooler.eval()\n",
    "        clsf.eval()\n",
    "\n",
    "        for x, label in val_loader:\n",
    "            x = x.to('cuda')\n",
    "            label = label.to('cuda')\n",
    "\n",
    "            rep = uni_sml(x, mode='straight', mask_rate=0.5)\n",
    "            # print(rep.shape)\n",
    "            logit = clsf(pooler(rep[:, 0])).squeeze()\n",
    "\n",
    "            _, pred = torch.max(logit.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (pred == label).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print('valid accuracy in %d epoch: %.4f' % ((epoch+1), accuracy))\n",
    "            print('-' * 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "def parse_annotation_file(json_file):\n",
    "    tracks = {}\n",
    "    with open(json_file) as f:\n",
    "        examples = json.load(f)\n",
    "        for song_id in examples:\n",
    "            tracks[song_id] = {\n",
    "                'track_id': examples[song_id]['extra']['songs_info']['song_id'],\n",
    "                'split': examples[song_id]['split'],\n",
    "                'labels': examples[song_id]['y']\n",
    "            }\n",
    "    return tracks\n",
    "\n",
    "infors = parse_annotation_file('clips_45seconds/emomusic.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 64\n",
    "sample_rate = 44100\n",
    "top_db = 80\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=2.0,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,\n",
    "    mel_scale=\"htk\",\n",
    ")\n",
    "ampl2db = AT.AmplitudeToDB(top_db=top_db)\n",
    "\n",
    "mel_list = []\n",
    "file_path = getListOfFiles('emo music')\n",
    "for wav_path in tqdm(file_path):\n",
    "    wav_id = wav_path[10: -4].zfill(4)\n",
    "\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        emotion = infors[wav_id]['labels']\n",
    "    except RuntimeError:\n",
    "        print(wav_path)\n",
    "        continue\n",
    "    except KeyError:\n",
    "        print(wav_id)\n",
    "        continue\n",
    "    # scaler = VT.Resize((64, 1938))\n",
    "    melspect = mel_spectrogram(waveform)\n",
    "    melspect = ampl2db(melspect)\n",
    "    melspect = (melspect).detach() * 0.01\n",
    "    # print(melspect.shape)\n",
    "    mel_list.append([melspect, emotion])\n",
    "\n",
    "class MuseData(Dataset):\n",
    "    def __init__(self, data, transform='None', mode='train', max_len=25):\n",
    "        # processed_data = []\n",
    "\n",
    "        x_shape = []\n",
    "        for idx, (x, l) in enumerate(data):\n",
    "            try:\n",
    "                x_shape.append(x.shape[-1])\n",
    "            except ValueError:\n",
    "                print(idx)\n",
    "        # x_shape = [l.shape[-1] for (l, _) in data]\n",
    "        self.max_len = max_len\n",
    "        # self.length_per_sec = int(np.max(np.array(x_shape)) // 128)\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data[idx]\n",
    "        ori_width = data.shape[-1]\n",
    "        ori_height = data.shape[-2]\n",
    "\n",
    "        if self.mode  == 'train':\n",
    "            width = random.randint(int(ori_width * 0.9), int(ori_width * 1.1))\n",
    "            scaler = VT.Resize((ori_height, width))\n",
    "            cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2 ))\n",
    "            # cropper(scaler(mel_list[0])).shape\n",
    "            brightness = random.uniform(0.9, 1.1)\n",
    "            mel = scaler(data)\n",
    "            mel = (cropper(mel) * brightness).detach()\n",
    "            # if self.mode == 'train':\n",
    "            #     mel = self.transform(mel)\n",
    "        else:\n",
    "            # cropper = VT.RandomCrop((ori_height, self.max_len * ori_height // 2))\n",
    "            # mel = cropper(data)\n",
    "            mel = data[..., :(self.max_len * ori_height) // 2 ]\n",
    "\n",
    "        split_mel = []\n",
    "        # print(mel.shape[2])\n",
    "        for idx in range(self.max_len):\n",
    "\n",
    "            piece = mel[:, :, idx*ori_height//2: (idx+1)*ori_height//2]\n",
    "            if piece.shape[-1] != ori_height//2:\n",
    "                print('Error piece')\n",
    "\n",
    "            # piece = torch.zeros(piece)\n",
    "            split_mel.append(piece)\n",
    "        split_mel = torch.stack(split_mel, dim=0)\n",
    "        return split_mel, torch.tensor(label[0]), torch.tensor(label[1])\n",
    "\n",
    "import random\n",
    "batch_size = 32\n",
    "random.shuffle(mel_list)\n",
    "\n",
    "\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8),len(dataset) - int(len(dataset) * 0.8)])\n",
    "train_set, val_set = MuseData(mel_list[:int(0.8 * len(mel_list))], None, 'train'), MuseData(mel_list[int(0.8*len(mel_list)):], None, 'val')\n",
    "# train_set = MuseData(train_data)\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# val_set = MuseData(val_data)\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CLSF(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.prob_valence = nn.Linear(config.hidden_size, 1)\n",
    "        self.prob_arousal = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.prob_valence(x), self.prob_arousal(x)\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 2000\n",
    "\n",
    "fe_config = ConfigFE(16, 320, 2, True, 256, 40)\n",
    "bert_config = BertConfig(hidden_size=256, num_attention_heads=4, num_hidden_layers=8, intermediate_size=1024, hidden_dropout_prob=0.1)\n",
    "\n",
    "uni_sml = UniSML(fe_config, bert_config).to('cuda')\n",
    "uni_sml.load_state_dict(torch.load('ckpt/uni_sml.pkl'))\n",
    "\n",
    "for param in uni_sml.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "class Pooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        # mean_hidden = hidden_states.mean(1)\n",
    "        pooled_output = self.dense(hidden_states)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "pooler = Pooler(bert_config).to('cuda')\n",
    "clsf = CLSF(bert_config).to('cuda')\n",
    "crit = nn.MSELoss()\n",
    "opt = torch.optim.AdamW(list(uni_sml.parameters()) + list(pooler.parameters()) + list(clsf.parameters()), lr=lr,\n",
    "                        weight_decay=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "scorer = R2Score().to('cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "acc_script = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    loss_script = []\n",
    "\n",
    "    uni_sml.train()\n",
    "    pooler.train()\n",
    "    clsf.train()\n",
    "\n",
    "    flag = 0\n",
    "    for x, label_v, label_a in train_loader:\n",
    "        x = x.to('cuda')\n",
    "        label_v = label_v.to('cuda')\n",
    "        label_a = label_a.to('cuda')\n",
    "\n",
    "        rep = uni_sml(x, mode='straight')\n",
    "\n",
    "        logit_v, logit_a = clsf(pooler(rep[:, 1:].mean(1)))\n",
    "        logit_v, logit_a = logit_v.squeeze(-1), logit_a.squeeze(-1)\n",
    "\n",
    "        loss = crit(logit_v, label_v) + crit(logit_a, label_a)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_script.append(loss.cpu().data.item())\n",
    "        if flag == 0:\n",
    "            total_label_v, total_label_a = label_v.data, label_a.data\n",
    "            total_logit_v, total_logit_a = logit_v.data, logit_a.data\n",
    "            flag = 1\n",
    "        else:\n",
    "            total_label_v = torch.cat([total_label_v, label_v.data], dim=0)\n",
    "            total_label_a = torch.cat([total_label_a, label_a.data], dim=0)\n",
    "\n",
    "            total_logit_v = torch.cat([total_logit_v, logit_v.data], dim=0)\n",
    "            total_logit_a = torch.cat([total_logit_a, logit_a.data], dim=0)\n",
    "\n",
    "    r2_v = scorer(total_logit_v, total_label_v)\n",
    "    r2_a = scorer(total_logit_a, total_label_a)\n",
    "\n",
    "    mean_loss = np.mean(np.array(loss_script))\n",
    "    train_losses.append(mean_loss)\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print('train loss in %d epoch: %.4f' % ((epoch+1), mean_loss))\n",
    "        print('r2 score valence: %.4f' % r2_v)\n",
    "        print('r2 score arousal: %.4f' % r2_a)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        uni_sml.eval()\n",
    "        pooler.eval()\n",
    "        clsf.eval()\n",
    "\n",
    "        for x, label_v, label_a in train_loader:\n",
    "            x = x.to('cuda')\n",
    "            label_v = label_v.to('cuda')\n",
    "            label_a = label_a.to('cuda')\n",
    "\n",
    "            rep = uni_sml(x, mode='straight', mask_rate=0.5)\n",
    "            # print(rep.shape)\n",
    "            logit_v, logit_a = clsf(pooler(rep[:, 1:].mean(1)))\n",
    "            logit_v, logit_a = logit_v.squeeze(-1), logit_a.squeeze(-1)\n",
    "\n",
    "            if flag == 0:\n",
    "                total_label_v, total_label_a = label_v.data, label_a.data\n",
    "                total_logit_v, total_logit_a = logit_v.data, logit_a.data\n",
    "                flag = 1\n",
    "            else:\n",
    "                total_label_v = torch.cat([total_label_v, label_v.data], dim=0)\n",
    "                total_label_a = torch.cat([total_label_a, label_a.data], dim=0)\n",
    "\n",
    "                total_logit_v = torch.cat([total_logit_v, logit_v.data], dim=0)\n",
    "                total_logit_a = torch.cat([total_logit_a, logit_a.data], dim=0)\n",
    "\n",
    "\n",
    "        r2_v = scorer(total_logit_v, total_label_v)\n",
    "        r2_a = scorer(total_logit_a, total_label_a)\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print('r2 score in %d epoch: %.4f, %.4f' % ((epoch+1), r2_v, r2_a))\n",
    "            print('-' * 30)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
